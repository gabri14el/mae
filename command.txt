python main_pretrain.py --batch_size 32 \
--epochs 3000 \
--model mae_vit_base_patch16 \
--mask_ratio 0.60 \
--warmup_epochs 30 \
--data_path /media/gabriel/BA1041B410417881/Users/gabrielc/Datasets/all_plus_utad \
--blr 1.5e-4 --weight_decay 0.05 \
--num_workers 1 \
--world_size 1 \
--resume output_dir/checkpoint-999.pth \
--start_epoch 1000



python main_pretrain.py --batch_size 64 \
--epochs 500 \
--model mae_vit_base_patch16 \
--mask_ratio 0.60 \
--warmup_epochs 10 \
--data_path /media/gabriel/BA1041B410417881/Users/gabrielc/Datasets/all_plus_utad \
--blr 1.5e-4 --weight_decay 0.05 \
--num_workers 1 \
--world_size 1 \
--output output_imagenet/base \
--log output_imagenet/base \
--checkpoint_encoder /home/gabriel/Projects/mae/mae_pretrain_vit_base.pth \
--start_epoch 0

python main_finetune.py \
--batch_size 196 \
--model vit_tiny_patch16 \
--finetune /home/gabriel/Projects/mae-main/output_pre_train_tiny/checkpoint-499.pth \
--epochs 100 \
--blr 1e-3 --layer_decay 0.65 \
--weight_decay 0.05 --drop_path 0.1 --reprob 0.25 --mixup 0.8 --cutmix 1.0 \
--warmup_epochs 10 \
--dist_eval --data_path /home/gabriel/Downloads/castas-huge2-split \
--output_dir ./output_ft_tiny \
--nb_classes 43 \
--num_workers 1 \
--log ./output_ft_tiny

%use the pretrain
python main_pretrain.py --batch_size 80 \
--epochs 2500 \
--model mae_vit_base_patch16 \
--mask_ratio 0.60 \
--warmup_epochs 10 \
--data_path /media/gabriel/BA1041B4104178811/Users/gabrielc/Datasets/all_plus_utad/ \
--blr 5e-4 --weight_decay 0.05 \
--num_workers 1 \
--world_size 1 \
--output output_imagenet_v2/base \
--log output_imagenet_v2/base \
--checkpoint_encoder /home/gabriel/Projects/mae/mae_pretrain_vit_base.pth \
--start_epoch 0

%visualize attention
python visualize_attention.py --arch vit_base_patch16 \
--pretrained_weights /media/gabriel/BA1041B4104178811/Users/gabrielc/Projects/mae/output_only_imagenet/ft/base/checkpoint.pth \
--image_path /home/gabriel/Pictures/castas/2024/raw/20240425/Cabernet Sauvignon/IMG_20240425_183211.jpg \
--decoder false
